{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aniketkumar2808/GenAI/blob/main/RAG/Exercises_Self_and_Multi_Query_Retrival_RAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Qg-pSW5rdPRI"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-community==0.3.3 langchain==0.3.5 langchain_google_genai langchain_chroma==0.1.4 tiktoken==0.8.0 langchain-text-splitters==0.3.0 beautifulsoup4==4.12.3 lark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "X-tsoLp9dPRJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBnIwWYuPOuizPW-q8PMoDrcVJv8vYUs2I\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.schema import Document\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "GRGlpC-neCb_"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 1 A Movie Filtering Challenge  \n",
        "\n",
        "Create a query to find movies from the dataset that are romantic comedies with a rating above 7.0 and released after the year 2000\n",
        "\n"
      ],
      "metadata": {
        "id": "jM5eowQxQYF3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "nvzQX0FDb2ep"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "docs = [\n",
        "    Document(\n",
        "        page_content=\"A poor but big-hearted man takes orphans into his home. After discovering his scientist father's invisibility device, he rises to the occasion and fights to save his children and all of India from the clutches of a greedy gangster\",\n",
        "        metadata={\"year\": 2006, \"director\": \"Rakesh Roshan\", \"rating\": 7.1, \"genre\": \"science fiction\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"The story of six young Indians who assist an English woman to film a documentary on the freedom fighters from their past, and the events that lead them to relive the long-forgotten saga of freedom\",\n",
        "        metadata={\"year\": 2006, \"director\": \"Rakeysh Omprakash Mehra\", \"rating\": 9.1, \"genre\": \"drama\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A depressed wealthy businessman finds his life changing after he meets a spunky and care-free young woman\",\n",
        "        metadata={\"year\": 2007, \"director\": \"Anurag Basu\", \"rating\": 6.8, \"genre\": \"romance\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A schoolteacher's world turns upside down when he realizes that his former student, who is now a world-famous artist, may have plagiarized his work\",\n",
        "        metadata={\"year\": 2023, \"director\": \"R. Balki\", \"rating\": 7.8, \"genre\": \"drama\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A man returns to his country in order to marry his childhood sweetheart and proceeds to create misunderstanding between the families\",\n",
        "        metadata={\"year\": 1995, \"director\": \"Aditya Chopra\", \"rating\": 8.1, \"genre\": \"romance\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"The story of an Indian army officer guarding a picket alone in the Kargil conflict between India and Pakistan\",\n",
        "        metadata={\"year\": 2003, \"director\": \"J.P. Dutta\", \"rating\": 7.9, \"genre\": \"war\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Three young men from different parts of India arrive in Mumbai, seeking fame and fortune\",\n",
        "        metadata={\"year\": 1975, \"director\": \"Ramesh Sippy\", \"rating\": 8.2, \"genre\": \"action\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A simple man from a village falls in love with his new neighbor. He enlists the help of his musical-theater friends to woo the lovely girl-next-door away from her music teacher\",\n",
        "        metadata={\"year\": 1990, \"director\": \"Sooraj Barjatya\", \"rating\": 7.7, \"genre\": \"musical\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"A young mute girl from Pakistan loses herself in India with no way to head back. A devoted man undertakes the task to get her back to her homeland and unite her with her family\",\n",
        "        metadata={\"year\": 2015, \"director\": \"Kabir Khan\", \"rating\": 8.0, \"genre\": \"drama\"},\n",
        "    ),\n",
        "    Document(\n",
        "        page_content=\"Three idiots embark on a quest for a lost buddy. This journey takes them on a hilarious and meaningful adventure through memory lane and gives them a chance to relive their college days\",\n",
        "        metadata={\"year\": 2009, \"director\": \"Rajkumar Hirani\", \"rating\": 9.4, \"genre\": \"comedy\"},\n",
        "    ),\n",
        "]\n",
        "\n",
        "vectorstore = Chroma.from_documents(docs, embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Hint"
      ],
      "metadata": {
        "id": "tPgOOmxm7keU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain.chains.query_constructor.base import AttributeInfo\n",
        "# from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "\n",
        "# # Define the metadata field information\n",
        "# metadata_field_info = [\n",
        "#     AttributeInfo(\n",
        "#         name=\"genre\",\n",
        "#         description=\"The genre of the movie.\",\n",
        "#         type=\"string\",\n",
        "#     ),\n",
        "#     AttributeInfo(\n",
        "#         name=\"year\",\n",
        "#         description=\"The year the movie was released\",\n",
        "#         type=\"integer\",\n",
        "#     ),\n",
        "#     AttributeInfo(\n",
        "#         name=\"director\",\n",
        "#         description=\"The name of the movie director\",\n",
        "#         type=\"string\",\n",
        "#     ),\n",
        "#     AttributeInfo(\n",
        "#         name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
        "#     ),\n",
        "#   ## Complete This code\n",
        "# ]\n",
        "# document_content_description = \"Brief summary of a movie\"\n",
        "# # Initialize the SelfQueryRetriever\n",
        "# llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\",google_api_key=\"AIzaSyBnIwWYuPOuizPW-q8PMoDrcVJv8vYUs2I\")\n",
        "# retriever = SelfQueryRetriever.from_llm(\n",
        "#     #complete the code\n",
        "#     llm,\n",
        "#     vectorstore,\n",
        "#     document_content_description,\n",
        "#     metadata_field_info,verbose=True\n",
        "# )\n",
        "\n",
        "# # Construct and execute the query\n",
        "# # Display the results"
      ],
      "metadata": {
        "id": "hEtHUtowQjZ9",
        "outputId": "05cc503f-5b21-46cc-c038-955f1a2e3d0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Cannot import lark, please install it with 'pip install lark'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-1798e2f4a1ea>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Initialize the SelfQueryRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatGoogleGenerativeAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gemini-2.0-flash\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgoogle_api_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AIzaSyBnIwWYuPOuizPW-q8PMoDrcVJv8vYUs2I\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m retriever = SelfQueryRetriever.from_llm(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m#complete the code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/retrievers/self_query/base.py\u001b[0m in \u001b[0;36mfrom_llm\u001b[0;34m(cls, llm, vectorstore, document_contents, metadata_field_info, structured_query_translator, chain_kwargs, enable_limit, use_original_query, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mstructured_query_translator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallowed_operators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             )\n\u001b[0;32m--> 342\u001b[0;31m         query_constructor = load_query_constructor_runnable(\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mdocument_contents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/base.py\u001b[0m in \u001b[0;36mload_query_constructor_runnable\u001b[0;34m(llm, document_contents, attribute_info, examples, allowed_comparators, allowed_operators, enable_limit, schema_prompt, fix_invalid, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mainfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeInfo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mainfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         )\n\u001b[0;32m--> 368\u001b[0;31m     output_parser = StructuredQueryOutputParser.from_components(\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mallowed_comparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_comparators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mallowed_operators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_operators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/base.py\u001b[0m in \u001b[0;36mfrom_components\u001b[0;34m(cls, allowed_comparators, allowed_operators, allowed_attributes, fix_invalid)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             ast_parse = get_parser(\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0mallowed_comparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_comparators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mallowed_operators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_operators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/parser.py\u001b[0m in \u001b[0;36mget_parser\u001b[0;34m(allowed_comparators, allowed_operators, allowed_attributes)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# QueryTransformer is None when Lark cannot be imported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mQueryTransformer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;34m\"Cannot import lark, please install it with 'pip install lark'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;31mImportError\u001b[0m: Cannot import lark, please install it with 'pip install lark'.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "source": [
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "\n",
        "# Define the metadata field information\n",
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"genre\",\n",
        "        description=\"The genre of the movie.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"year\",\n",
        "        description=\"The year the movie was released\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"director\",\n",
        "        description=\"The name of the movie director\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"rating\", description=\"A 1-10 rating for the movie\", type=\"float\"\n",
        "    ),\n",
        "  ## Complete This code\n",
        "]\n",
        "document_content_description = \"Brief summary of a movie\"\n",
        "# Initialize the SelfQueryRetriever\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\")\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    #complete the code\n",
        "    llm,\n",
        "    vectorstore,\n",
        "    document_content_description,\n",
        "    metadata_field_info,verbose=True\n",
        ")\n",
        "\n",
        "# Construct and execute the query\n",
        "# Display the results"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "vjsz5AMLiBXW",
        "outputId": "edafa4f8-352a-44ae-eaae-13d342df3d0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "Cannot import lark, please install it with 'pip install lark'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-c572bcd56c70>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Initialize the SelfQueryRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mChatGoogleGenerativeAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gemini-2.0-flash\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m retriever = SelfQueryRetriever.from_llm(\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m#complete the code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/retrievers/self_query/base.py\u001b[0m in \u001b[0;36mfrom_llm\u001b[0;34m(cls, llm, vectorstore, document_contents, metadata_field_info, structured_query_translator, chain_kwargs, enable_limit, use_original_query, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mstructured_query_translator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallowed_operators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             )\n\u001b[0;32m--> 342\u001b[0;31m         query_constructor = load_query_constructor_runnable(\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mllm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mdocument_contents\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/base.py\u001b[0m in \u001b[0;36mload_query_constructor_runnable\u001b[0;34m(llm, document_contents, attribute_info, examples, allowed_comparators, allowed_operators, enable_limit, schema_prompt, fix_invalid, **kwargs)\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mainfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mainfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeInfo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mainfo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         )\n\u001b[0;32m--> 368\u001b[0;31m     output_parser = StructuredQueryOutputParser.from_components(\n\u001b[0m\u001b[1;32m    369\u001b[0m         \u001b[0mallowed_comparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_comparators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m         \u001b[0mallowed_operators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_operators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/base.py\u001b[0m in \u001b[0;36mfrom_components\u001b[0;34m(cls, allowed_comparators, allowed_operators, allowed_attributes, fix_invalid)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m             ast_parse = get_parser(\n\u001b[0m\u001b[1;32m    102\u001b[0m                 \u001b[0mallowed_comparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_comparators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mallowed_operators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallowed_operators\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain/chains/query_constructor/parser.py\u001b[0m in \u001b[0;36mget_parser\u001b[0;34m(allowed_comparators, allowed_operators, allowed_attributes)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;31m# QueryTransformer is None when Lark cannot be imported.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mQueryTransformer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         raise ImportError(\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;34m\"Cannot import lark, please install it with 'pip install lark'.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         )\n",
            "\u001b[0;31mImportError\u001b[0m: Cannot import lark, please install it with 'pip install lark'.",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exercise 2 : Multi-Query Retrieval for Research Papers: Exploring Diverse Perspectives\n",
        "\n",
        "Use the Multi-Query Retriever to retrieve documents related to a specific question about \"machine learning model interpretability\" from a collection of research papers. Observe how the retriever generates multiple queries to improve search results and retrieve diverse and relevant documents\n"
      ],
      "metadata": {
        "id": "xlSPMVX1AQRt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "Y_hloh_V7lxX",
        "outputId": "50e8bfcf-0a06-44dc-df69-d8a344f6bb7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
        "\n",
        "# Load a research paper and split it into chunks\n",
        "loader = PyPDFLoader(\"/content/sample_data/NIPS-2017-attention-is-all-you-need-Paper.pdf\")  # Replace with the path to your PDF\n",
        "data = loader.load()\n",
        "\n",
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
        "splits = text_splitter.split_documents(data)\n",
        "# Create a vector database\n",
        "# Initialize the MultiQueryRetriever\n",
        "\n",
        "# VectorDB\n",
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=\"AIzaSyBnIwWYuPOuizPW-q8PMoDrcVJv8vYUs2I\")\n",
        "vectordb = Chroma.from_documents(documents=splits, embedding=embedding)\n",
        "\n",
        "# Define the question\n",
        "question = \"Explain the architecture of transformer model\"\n",
        "\n",
        "# Retrieve documents using the MultiQueryRetriever\n",
        "llm = ChatGoogleGenerativeAI(model = \"gemini-2.0-flash\", temperature=0)\n",
        "retriever_from_llm = MultiQueryRetriever.from_llm(retriever=vectordb.as_retriever(),\n",
        "                                                  llm=llm)\n",
        "# Display the number of unique documents retrieved\n",
        "unique_docs = retriever_from_llm.invoke(question)\n",
        "print(len(unique_docs))\n",
        "print(unique_docs)"
      ],
      "metadata": {
        "id": "fQYRPWFWASUe",
        "outputId": "b05c293b-880e-4f29-c853-5daa8ddd18d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "[Document(metadata={'page': 1, 'source': '/content/sample_data/NIPS-2017-attention-is-all-you-need-Paper.pdf'}, page_content='the number of operations required to relate signals from two arbitrary input or output positions grows\\nin the distance between positions, linearly for ConvS2S and logarithmically for ByteNet. This makes\\nit more difﬁcult to learn dependencies between distant positions [ 11]. In the Transformer this is\\nreduced to a constant number of operations, albeit at the cost of reduced effective resolution due\\nto averaging attention-weighted positions, an effect we counteract with Multi-Head Attention as'), Document(metadata={'page': 1, 'source': '/content/sample_data/NIPS-2017-attention-is-all-you-need-Paper.pdf'}, page_content='sequence (y1,...,y m) of symbols one element at a time. At each step the model is auto-regressive\\n[9], consuming the previously generated symbols as additional input when generating the next.\\nThe Transformer follows this overall architecture using stacked self-attention and point-wise, fully\\nconnected layers for both the encoder and decoder, shown in the left and right halves of Figure 1,\\nrespectively.\\n3.1 Encoder and Decoder Stacks'), Document(metadata={'page': 4, 'source': '/content/sample_data/NIPS-2017-attention-is-all-you-need-Paper.pdf'}, page_content='3.2.3 Applications of Attention in our Model\\nThe Transformer uses multi-head attention in three different ways:\\n• In \"encoder-decoder attention\" layers, the queries come from the previous decoder layer,\\nand the memory keys and values come from the output of the encoder. This allows every\\nposition in the decoder to attend over all positions in the input sequence. This mimics the\\ntypical encoder-decoder attention mechanisms in sequence-to-sequence models such as\\n[31, 2, 8].')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zF_aHlQHAsaf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}